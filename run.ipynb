{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from torch.optim import Adam\n",
    "from abc_py.interface import ABC\n",
    "import functools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_constraint_table = {\n",
    "    \"adder.aig\": 2400,\n",
    "    \"bar.aig\": 120,\n",
    "    \"div.aig\": 64000,\n",
    "    \"hyp.aig\": 94000,\n",
    "    \"log2.aig\": 4000,\n",
    "    \"max.aig\": 2345,\n",
    "    \"multiplier.aig\": 2700,\n",
    "    \"sin.aig\": 2000,\n",
    "    \"sqrt.aig\": 34000,\n",
    "    \"square.aig\": 2300\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvantageActorCritic(nn.Module):\n",
    "    def __init__(self, input_dim, n_actions, gamma):\n",
    "        super(AdvantageActorCritic, self).__init__()\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.pi1 = nn.Linear(input_dim, 20)\n",
    "        self.pi2 = nn.Linear(20, 20)\n",
    "        self.pi = nn.Linear(20, n_actions)\n",
    "\n",
    "        self.v1 = nn.Linear(input_dim, 20)\n",
    "        self.v = nn.Linear(20, 1)\n",
    "\n",
    "        self.rewards = []\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "\n",
    "    def remember(self, state, action, reward):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, state):\n",
    "        pi1 = F.relu(self.pi1(state))\n",
    "        pi2 = F.relu(self.pi2(pi1))\n",
    "        pi = self.pi(pi2)\n",
    "\n",
    "        v1 = F.relu(self.v1(state))\n",
    "        v = F.leaky_relu(self.v(v1), 0.2)\n",
    "\n",
    "        return pi, v\n",
    "    \n",
    "    def calc_R(self):\n",
    "        states = torch.stack(self.states)\n",
    "        _, v = self.forward(states)\n",
    "\n",
    "        R = v[-1]\n",
    "        batch_return = []\n",
    "        for reward in self.rewards[::-1]:\n",
    "            R = reward + self.gamma * R\n",
    "            batch_return.append(R)\n",
    "\n",
    "        batch_return.reverse()\n",
    "        return torch.tensor(batch_return, dtype=torch.float)\n",
    "    \n",
    "    def calc_loss(self, final_state: torch.Tensor):\n",
    "        states = torch.stack(self.states)\n",
    "        actions = torch.tensor(self.actions, dtype=torch.float)\n",
    "        returns = self.calc_R()\n",
    "\n",
    "        pi, values = self.forward(states)\n",
    "        values = values.squeeze()\n",
    "        final_state = final_state.unsqueeze(0)\n",
    "        final_value = self.forward(final_state)[1].squeeze(0)\n",
    "        next_values = torch.cat((values[1:], final_value), dim=0)\n",
    "        td_error = returns + (self.gamma * next_values) - values\n",
    "\n",
    "        critic_loss = td_error ** 2\n",
    "        probs = F.softmax(pi, dim=1)\n",
    "        dist = Categorical(probs)\n",
    "        log_probs = dist.log_prob(actions)\n",
    "        actor_loss = -log_probs * td_error.detach()\n",
    "\n",
    "        total_loss = (actor_loss + critic_loss).mean()\n",
    "        return total_loss\n",
    "\n",
    "    def select_action(self, observation):\n",
    "        state = observation.unsqueeze(0)\n",
    "        pi, _ = self.forward(state)\n",
    "        probs = F.softmax(pi, dim=1)\n",
    "        dist = Categorical(probs)\n",
    "        action = dist.sample().item()\n",
    "\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_action(abc: ABC, area, delay, action, possible_actions, filename):\n",
    "    new_stats = possible_actions[action](abc)\n",
    "    observation_ = torch.tensor(new_stats[:6], dtype=torch.float)\n",
    "    new_area, new_delay = new_stats[6], new_stats[7]\n",
    "\n",
    "    if new_delay <= delay_constraint_table[filename]:\n",
    "        if new_area < area:\n",
    "            reward = 3\n",
    "        elif new_area > area:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward = 0\n",
    "    elif new_delay < delay:\n",
    "        if new_area < area:\n",
    "            reward = 3\n",
    "        elif new_area > area:\n",
    "            reward = 0.5\n",
    "        else:\n",
    "            reward = 2\n",
    "    elif new_delay > delay:\n",
    "        if new_area < area:\n",
    "            reward = 0\n",
    "        elif new_area > area:\n",
    "            reward = -3\n",
    "        else:\n",
    "            reward = -2\n",
    "    else:\n",
    "        if new_area < area:\n",
    "            reward = 3\n",
    "        elif new_area > area:\n",
    "            reward = -2\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "    return observation_, new_area, new_delay, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(actor_critic: AdvantageActorCritic, optimizer, episodes, iterations, abc: ABC, input_dim, possible_actions):\n",
    "    filelist = os.listdir('benchmarks/arithmetic')\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        avg_loss = torch.tensor(0., dtype=torch.float)\n",
    "        avg_score = torch.tensor(0., dtype=torch.float)\n",
    "        avg_area = torch.tensor(0., dtype=torch.float)\n",
    "        avg_delay = torch.tensor(0., dtype=torch.float)\n",
    "        constraints_met = 0\n",
    "\n",
    "        for filename in filelist:\n",
    "            if not filename.endswith('.aig') or filename == \"hyp.aig\":\n",
    "                continue\n",
    "\n",
    "            abc.read_aiger(f\"benchmarks/arithmetic/{filename}\")\n",
    "            init_stats = abc.read_libraries(\"libraries/asap7sc7p5t_INVBUF_RVT_FF_nldm_201020.lib\", \"libraries/asap7sc7p5t_SIMPLE_RVT_FF_nldm_201020.lib\")\n",
    "            observation, area, delay = torch.tensor([1] * input_dim, dtype=torch.float), init_stats[6], init_stats[7]\n",
    "            observation[0] = init_stats[0] / 512\n",
    "            observation[1] = init_stats[1] / 130\n",
    "\n",
    "            init_area = area\n",
    "            init_delay = delay\n",
    "            init_stats = torch.tensor(init_stats[:6], dtype=torch.float)\n",
    "\n",
    "            score = 0\n",
    "            actor_critic.clear_memory()\n",
    "\n",
    "            for _ in range(iterations):\n",
    "                action = actor_critic.select_action(observation)\n",
    "                observation_, new_area, new_delay, reward = perform_action(abc, area, delay, action, possible_actions, filename)\n",
    "                observation_ = observation_ / init_stats\n",
    "\n",
    "                if init_stats[2] == 0:\n",
    "                    observation_[2] = 0.0\n",
    "                observation_[0] = init_stats[0] / 512\n",
    "                observation_[1] = init_stats[1] / 130\n",
    "\n",
    "                score += reward\n",
    "                actor_critic.remember(observation, action, reward)\n",
    "                observation = observation_\n",
    "                area = new_area\n",
    "                delay = new_delay\n",
    "\n",
    "            loss = actor_critic.calc_loss(observation_)\n",
    "            avg_loss += loss.detach().item()\n",
    "            avg_area += area / init_area\n",
    "            avg_delay += delay / init_delay\n",
    "            avg_score += score\n",
    "            if delay <= delay_constraint_table[filename]:\n",
    "                constraints_met += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            actor_critic.clear_memory()\n",
    "\n",
    "        avg_loss = (avg_loss * 4) / len(filelist)\n",
    "        avg_area = (avg_area * 4) / len(filelist)\n",
    "        avg_delay = (avg_delay * 4) / len(filelist)\n",
    "        avg_score = (avg_score * 4) / len(filelist)\n",
    "        print(f\"Episode {episode + 1}: loss {avg_loss} area {avg_area} delay {avg_delay} constraints met {constraints_met}/{len(filelist) / 4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_actions = [\n",
    "    functools.partial(ABC.resub, zero_cost=False, preserve_levels=True),\n",
    "    functools.partial(ABC.resub, zero_cost=True, preserve_levels=True),\n",
    "    functools.partial(ABC.rewrite, zero_cost=False, preserve_levels=True, verbose=False),\n",
    "    functools.partial(ABC.rewrite, zero_cost=True, preserve_levels=True, verbose=False),\n",
    "    functools.partial(ABC.refactor, zero_cost=False, preserve_levels=True),\n",
    "    functools.partial(ABC.refactor, zero_cost=True, preserve_levels=True),\n",
    "    functools.partial(ABC.balance),\n",
    "    functools.partial(ABC.balance),\n",
    "]\n",
    "\n",
    "n_actions = len(possible_actions)\n",
    "input_dim = 6\n",
    "learning_rate = 3e-4\n",
    "gamma = 0.9\n",
    "epochs = 20\n",
    "iterations = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_critic = AdvantageActorCritic(input_dim, n_actions, gamma)\n",
    "optimiser = Adam(actor_critic.parameters(), lr=learning_rate)\n",
    "abc = ABC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: loss 58.20940399169922 area 0.9750029444694519 delay 0.7612615823745728 constraints met 7/10.0\n",
      "Episode 2: loss 41.511497497558594 area 1.011614441871643 delay 0.7720639705657959 constraints met 7/10.0\n",
      "Episode 3: loss 59.573081970214844 area 1.0103243589401245 delay 0.7631706595420837 constraints met 7/10.0\n",
      "Episode 4: loss 46.49177169799805 area 1.0292069911956787 delay 0.7630993127822876 constraints met 7/10.0\n",
      "Episode 5: loss 35.73936462402344 area 0.9701582789421082 delay 0.7575303316116333 constraints met 7/10.0\n",
      "Episode 6: loss 42.56972122192383 area 0.9893997311592102 delay 0.7810378670692444 constraints met 6/10.0\n",
      "Episode 7: loss 42.03363800048828 area 0.992631733417511 delay 0.7678967118263245 constraints met 7/10.0\n",
      "Episode 8: loss 30.94564437866211 area 0.989105224609375 delay 0.7630956172943115 constraints met 7/10.0\n",
      "Episode 9: loss 53.030250549316406 area 0.9652625322341919 delay 0.7563589811325073 constraints met 7/10.0\n",
      "Episode 10: loss 38.91315460205078 area 0.9705926179885864 delay 0.771474301815033 constraints met 7/10.0\n",
      "Episode 11: loss 34.01236343383789 area 0.988057017326355 delay 0.7658246755599976 constraints met 7/10.0\n",
      "Episode 12: loss 32.330406188964844 area 0.9767856597900391 delay 0.7560511827468872 constraints met 7/10.0\n",
      "Episode 13: loss 30.039133071899414 area 0.9658266305923462 delay 0.7672140002250671 constraints met 7/10.0\n",
      "Episode 14: loss 46.50038528442383 area 0.9717578887939453 delay 0.7783012986183167 constraints met 7/10.0\n",
      "Episode 15: loss 45.819541931152344 area 0.9916954040527344 delay 0.7583826184272766 constraints met 7/10.0\n",
      "Episode 16: loss 58.26688766479492 area 0.9602506756782532 delay 0.763919472694397 constraints met 6/10.0\n",
      "Episode 17: loss 38.20650863647461 area 1.003090262413025 delay 0.7536481022834778 constraints met 7/10.0\n",
      "Episode 18: loss 54.29856491088867 area 0.9738155603408813 delay 0.7623659372329712 constraints met 7/10.0\n",
      "Episode 19: loss 31.422021865844727 area 0.9872616529464722 delay 0.7632413506507874 constraints met 7/10.0\n",
      "Episode 20: loss 41.693748474121094 area 0.9775084257125854 delay 0.7585615515708923 constraints met 6/10.0\n"
     ]
    }
   ],
   "source": [
    "train(actor_critic, optimiser, epochs, iterations, abc, input_dim, possible_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(actor_critic, \"actor_critic4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14113/1976584352.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  actor_critic = torch.load(\"actor_critic4.pth\")\n"
     ]
    }
   ],
   "source": [
    "actor_critic = torch.load(\"actor_critic4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: square.aig, initial area: 1096.52, initial delay: 2401.29, final area: 1089.62, final delay: 2377.67\n",
      "Filename: hyp.aig, initial area: 13041.75, initial delay: 166839.98, final area: 14727.64, final delay: 135089.5\n",
      "Filename: adder.aig, initial area: 58.68, initial delay: 2445.81, final area: 73.28, final delay: 2265.86\n",
      "Filename: sin.aig, initial area: 295.81, initial delay: 1990.54, final area: 329.95, final delay: 1739.05\n",
      "Filename: bar.aig, initial area: 155.64, initial delay: 151.33, final area: 174.07, final delay: 173.1\n",
      "Filename: max.aig, initial area: 167.8, initial delay: 2626.79, final area: 186.78, final delay: 2292.29\n",
      "Filename: sqrt.aig, initial area: 1139.18, initial delay: 65898.94, final area: 1413.68, final delay: 35446.91\n",
      "Filename: div.aig, initial area: 2982.86, initial delay: 64616.92, final area: 2753.44, final delay: 39649.43\n",
      "Filename: multiplier.aig, initial area: 1469.97, initial delay: 2563.76, final area: 1383.48, final delay: 2530.95\n",
      "Filename: log2.aig, initial area: 1621.4, initial delay: 4099.14, final area: 1654.39, final delay: 3449.46\n"
     ]
    }
   ],
   "source": [
    "def generate_actions(actor_critic: AdvantageActorCritic, iterations, input_dim, possible_actions, filename):\n",
    "    abc = ABC()\n",
    "    abc.read_aiger(f\"benchmarks/arithmetic/{filename}\")\n",
    "    init_stats = abc.read_libraries(\"libraries/asap7sc7p5t_INVBUF_RVT_FF_nldm_201020.lib\", \"libraries/asap7sc7p5t_SIMPLE_RVT_FF_nldm_201020.lib\")\n",
    "    observation, area, delay = torch.tensor([1] * input_dim, dtype=torch.float), init_stats[6], init_stats[7]\n",
    "    iarea, idelay = area, delay\n",
    "    observation[0] = init_stats[0] / 512\n",
    "    observation[1] = init_stats[1] / 130\n",
    "\n",
    "    init_stats = torch.tensor(init_stats[:6], dtype=torch.float)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        actor_critic.clear_memory()\n",
    "\n",
    "        for _ in range(iterations):\n",
    "            action = actor_critic.select_action(observation)\n",
    "            observation_, new_area, new_delay, reward = perform_action(abc, area, delay, action, possible_actions, filename)\n",
    "            observation_ = observation_ / init_stats\n",
    "\n",
    "            if init_stats[2] == 0:\n",
    "                observation_[2] = 0.0\n",
    "            observation_[0] = init_stats[0] / 512\n",
    "            observation_[1] = init_stats[1] / 130\n",
    "\n",
    "            actor_critic.remember(observation, action, reward)\n",
    "            observation = observation_\n",
    "            area = new_area\n",
    "            delay = new_delay\n",
    "\n",
    "        actions = actor_critic.actions\n",
    "        actor_critic.clear_memory()\n",
    "        return actions, iarea, idelay, area, delay, abc.quit()\n",
    "    \n",
    "for filename in os.listdir(\"benchmarks/arithmetic/\"):\n",
    "    if not filename.endswith('.aig'):\n",
    "        continue\n",
    "\n",
    "    _, iarea, idelay, area, delay, _ = generate_actions(actor_critic, iterations, input_dim, possible_actions, filename)\n",
    "    print(f\"Filename: {filename}, initial area: {iarea}, initial delay: {idelay}, final area: {area}, final delay: {delay}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
